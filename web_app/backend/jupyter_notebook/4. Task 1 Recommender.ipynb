{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "1fe55321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcf8b4",
   "metadata": {},
   "source": [
    "# Load LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "a8da5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_disk=gensim.models.ldamodel.LdaModel.load(\"Model/finalmodel_5Topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "d51f6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary.load('Model/finalmodel_Dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0edfa",
   "metadata": {},
   "source": [
    "# Extract & Preprocess Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "84b736a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus_1974 = preprocess.load_corpus('Data/Test/Chapters/5827')\n",
    "\n",
    "test_ids = test_corpus_1974.fileids()\n",
    "chapters_name = [id.replace('.txt','') for id in test_ids]\n",
    "\n",
    "test_docs_1974 = preprocess.corpus2docs(test_corpus_1974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "2bbfd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(bigram_mod, texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(bigram_mod, trigram_mod, texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "1c273180",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(test_docs_1974, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[test_docs_1974], threshold=50)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "docs_bigrams = make_bigrams(bigram_mod, test_docs_1974)\n",
    "data_bigrams_trigrams = make_trigrams(bigram_mod, trigram_mod, docs_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "b3fa2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs_1974 = preprocess.docs2vecs(data_bigrams_trigrams, id2word)\n",
    "similarity = similarities.MatrixSimilarity(lda_disk[test_vecs_1974])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "a2f5dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test doc0: [(0, 0.2092944), (1, 0.04010017), (2, 0.66173494), (3, 0.012143663), (4, 0.07672681)]\n",
      "Closest Topic: Topic 2\n",
      "test doc1: [(0, 0.06492638), (1, 0.074570395), (2, 0.5798887), (4, 0.27246475)]\n",
      "Closest Topic: Topic 2\n",
      "test doc2: [(0, 0.010751086), (1, 0.19740404), (2, 0.56492525), (4, 0.22044188)]\n",
      "Closest Topic: Topic 2\n",
      "test doc3: [(0, 0.07416345), (1, 0.09154141), (2, 0.39488274), (4, 0.43103626)]\n",
      "Closest Topic: Topic 4\n",
      "test doc4: [(0, 0.018251669), (1, 0.10464484), (2, 0.48008782), (3, 0.025361067), (4, 0.3716546)]\n",
      "Closest Topic: Topic 2\n",
      "test doc5: [(0, 0.08246775), (1, 0.09601282), (2, 0.5152149), (3, 0.01635788), (4, 0.28994665)]\n",
      "Closest Topic: Topic 2\n",
      "test doc6: [(0, 0.13596003), (1, 0.13214675), (2, 0.25238892), (3, 0.041432526), (4, 0.43807176)]\n",
      "Closest Topic: Topic 4\n",
      "test doc7: [(0, 0.09320552), (1, 0.11042821), (2, 0.50177413), (4, 0.29451278)]\n",
      "Closest Topic: Topic 2\n",
      "test doc8: [(0, 0.054623727), (1, 0.012102318), (2, 0.3786071), (3, 0.012749717), (4, 0.54191715)]\n",
      "Closest Topic: Topic 4\n",
      "test doc9: [(0, 0.0981658), (1, 0.086479604), (2, 0.38002738), (3, 0.010314904), (4, 0.42501235)]\n",
      "Closest Topic: Topic 4\n",
      "test doc10: [(0, 0.020664724), (1, 0.023981458), (2, 0.5628186), (4, 0.38926134)]\n",
      "Closest Topic: Topic 2\n",
      "test doc11: [(0, 0.18775201), (1, 0.11510485), (2, 0.36881503), (3, 0.022529079), (4, 0.30579904)]\n",
      "Closest Topic: Topic 2\n",
      "test doc12: [(0, 0.096367344), (1, 0.08918858), (2, 0.51799345), (3, 0.017137505), (4, 0.27931312)]\n",
      "Closest Topic: Topic 2\n",
      "test doc13: [(0, 0.1124137), (1, 0.06584464), (2, 0.3735886), (4, 0.4481092)]\n",
      "Closest Topic: Topic 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    sim_topic = max(vector,key=lambda item:item[1])\n",
    "    print(\"test doc\" + str(i) + \": \" + str(vector))\n",
    "    print(\"Closest Topic: Topic \" + str(sim_topic[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "b9f1ae0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conception', 0.03775606),\n",
       " ('zarathustra', 0.028077127),\n",
       " ('thou', 0.024449555),\n",
       " ('hath', 0.018459603),\n",
       " ('pure', 0.016960025),\n",
       " ('phenomenon', 0.015507126),\n",
       " ('thee', 0.0153419515),\n",
       " ('unto', 0.01463752),\n",
       " ('cognition', 0.013255156),\n",
       " ('intuition', 0.013230192),\n",
       " ('empirical', 0.010757555),\n",
       " ('social', 0.010513507),\n",
       " ('activity', 0.010492589),\n",
       " ('education', 0.0104921805),\n",
       " ('representation', 0.009958939),\n",
       " ('priori', 0.009342978),\n",
       " ('verily', 0.009038341),\n",
       " ('doth', 0.008945876),\n",
       " ('space', 0.008808358),\n",
       " ('transcendental', 0.008680221)]"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = lda_disk.show_topic(0, topn=len(id2word))\n",
    "topic_word[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def5c027",
   "metadata": {},
   "source": [
    "## Model 1 - Using Similarity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f39de",
   "metadata": {},
   "source": [
    "### Top Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "863307a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_num = 0\n",
    "vector = lda_disk[test_vecs_1974[chap_num]]\n",
    "sim_topic = max(vector,key=lambda item:item[1])\n",
    "top_topic = sim_topic[0]\n",
    "top_topic\n",
    "topic_word = lda_disk.show_topic(top_topic, topn=len(id2word))\n",
    "# topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "70ffb899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'acquire',\n",
       " 'action',\n",
       " 'adopt',\n",
       " 'advance',\n",
       " 'afford',\n",
       " 'affords',\n",
       " 'agree',\n",
       " 'almost',\n",
       " 'along']"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_words = [id2word[i[0]] for i in test_vecs_1974[chap_num]]\n",
    "selected_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "0813b3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words = []\n",
    "\n",
    "keyword_type = 'bigrams'\n",
    "for word in topic_word:\n",
    "    if(keyword_type == 'unigrams'):\n",
    "        if (len(key_words) < 5) & (word [0] in selected_words):\n",
    "            key_words.append(word)\n",
    "    else:\n",
    "        if ('_' in word[0]) & (len(key_words) < 5) & (word [0] in selected_words):\n",
    "            key_words.append(word)\n",
    "\n",
    "key_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd48b8",
   "metadata": {},
   "source": [
    "### Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "e6ac2de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER_III__THE_NATURE_OF_MATTER',\n",
       " 'CHAPTER_II__THE_EXISTENCE_OF_MATTER',\n",
       " 'CHAPTER_IV__IDEALISM',\n",
       " 'CHAPTER_IX__THE_WORLD_OF_UNIVERSALS',\n",
       " 'CHAPTER_I__APPEARANCE_AND_REALITY',\n",
       " 'CHAPTER_VIII__HOW__A_PRIORI__KNOWLEDGE_IS_POSSIBLE',\n",
       " 'CHAPTER_VII__ON_OUR_KNOWLEDGE_OF_GENERAL_PRINCIPLES',\n",
       " 'CHAPTER_VI__ON_INDUCTION',\n",
       " 'CHAPTER_V__KNOWLEDGE_BY_ACQUAINTANCE_AND_KNOWLEDGE_BY_DESCRIPTION',\n",
       " 'CHAPTER_XIII__KNOWLEDGE,_ERROR,_AND_PROBABLE_OPINION',\n",
       " 'CHAPTER_XII__TRUTH_AND_FALSEHOOD',\n",
       " 'CHAPTER_XIV__THE_LIMITS_OF_PHILOSOPHICAL_KNOWLEDGE',\n",
       " 'CHAPTER_XI__ON_INTUITIVE_KNOWLEDGE',\n",
       " 'CHAPTER_X__ON_OUR_KNOWLEDGE_OF_UNIVERSALS']"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "baf41b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Recommended Chapters:\n",
      "1. CHAPTER_X__ON_OUR_KNOWLEDGE_OF_UNIVERSALS(0.98627436)\n",
      "2. CHAPTER_IX__THE_WORLD_OF_UNIVERSALS(0.9811799)\n",
      "3. CHAPTER_XIII__KNOWLEDGE,_ERROR,_AND_PROBABLE_OPINION(0.9807602)\n"
     ]
    }
   ],
   "source": [
    "chap_num = 8\n",
    "\n",
    "chosen_chapter = chapters_name[chap_num]\n",
    "recommendation_scores = []\n",
    "\n",
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    sim_topic = max(vector,key=lambda item:item[1])\n",
    "    \n",
    "    if(i == chap_num):\n",
    "        sims = similarity[vector]\n",
    "        sims = list(enumerate(sims))\n",
    "        for sim in sims:\n",
    "            chapter_num = sim[0]\n",
    "            recommendation_score = [chapters_name[chapter_num], sim[1]]\n",
    "            recommendation_scores.append(recommendation_score)\n",
    "        \n",
    "recommendation_scores = sorted(recommendation_scores, key=lambda x: x[1], reverse=True)     \n",
    "recommendation = []\n",
    "\n",
    "\n",
    "print('Top 3 Recommended Chapters:')\n",
    "for i in range(1,4):\n",
    "    recommendation.append((recommendation_scores[i][0], recommendation_scores[i][1]))\n",
    "    print(f'{i}. {str(recommendation_scores[i][0])}({str(recommendation_scores[i][1])})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000b96f",
   "metadata": {},
   "source": [
    "## Model 2 - Using Distribution of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "4737a130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER_III__THE_NATURE_OF_MATTER',\n",
       " 'CHAPTER_II__THE_EXISTENCE_OF_MATTER',\n",
       " 'CHAPTER_IV__IDEALISM',\n",
       " 'CHAPTER_IX__THE_WORLD_OF_UNIVERSALS',\n",
       " 'CHAPTER_I__APPEARANCE_AND_REALITY',\n",
       " 'CHAPTER_VIII__HOW__A_PRIORI__KNOWLEDGE_IS_POSSIBLE',\n",
       " 'CHAPTER_VII__ON_OUR_KNOWLEDGE_OF_GENERAL_PRINCIPLES',\n",
       " 'CHAPTER_VI__ON_INDUCTION',\n",
       " 'CHAPTER_V__KNOWLEDGE_BY_ACQUAINTANCE_AND_KNOWLEDGE_BY_DESCRIPTION',\n",
       " 'CHAPTER_XIII__KNOWLEDGE,_ERROR,_AND_PROBABLE_OPINION',\n",
       " 'CHAPTER_XII__TRUTH_AND_FALSEHOOD',\n",
       " 'CHAPTER_XIV__THE_LIMITS_OF_PHILOSOPHICAL_KNOWLEDGE',\n",
       " 'CHAPTER_XI__ON_INTUITIVE_KNOWLEDGE',\n",
       " 'CHAPTER_X__ON_OUR_KNOWLEDGE_OF_UNIVERSALS']"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "b311403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Recommended Chapters:\n",
      "1. CHAPTER_II__THE_EXISTENCE_OF_MATTER\n",
      "2. CHAPTER_IV__IDEALISM\n",
      "3. CHAPTER_XII__TRUTH_AND_FALSEHOOD\n"
     ]
    }
   ],
   "source": [
    "# if first digit in tuple matches, store doc\n",
    "# reco_docs -- dont remove user input\n",
    "# - get index of user input within reco_docs\n",
    "# - compare difference between first topic probability and store as list; e.g. {4: 0.002,...}\n",
    "# - take top 5 minimum difference\n",
    "\n",
    "j = 0\n",
    "vector_selected = lda_disk[test_vecs_1974[j]]\n",
    "vector_selected.sort(key=lambda x: x[1], reverse=True)\n",
    "vector_selected\n",
    "\n",
    "reco_docs = {}\n",
    "\n",
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    vector.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if (vector[0][0]==vector_selected[0][0]) & (vector[1][0] == vector_selected[1][0]):\n",
    "        reco_docs[i] = vector\n",
    "        # print(vector[0][1])\n",
    "\n",
    "# print(reco_docs)\n",
    "input_topic = reco_docs[j]\n",
    "\n",
    "# Remove user input\n",
    "if j in reco_docs.keys():\n",
    "    reco_docs.pop(j)\n",
    "\n",
    "# if there's no 2 same topics\n",
    "if reco_docs == {}:\n",
    "    for i in range(0,len(test_vecs_1974)):\n",
    "        vector = lda_disk[test_vecs_1974[i]]\n",
    "        vector.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        if (vector[0][0]==vector_selected[0][0]):\n",
    "            reco_docs[i] = vector\n",
    "\n",
    "    # Remove user input\n",
    "    if j in reco_docs.keys():\n",
    "        reco_docs.pop(j)\n",
    "\n",
    "diff = \"\"\n",
    "diff_dict = {}\n",
    "for x, y in reco_docs.items():\n",
    "    diff = abs(input_topic[0][1] - reco_docs[x][0][1])\n",
    "    diff_dict[x] = diff\n",
    "\n",
    "diff_dict = sorted(diff_dict.items(), key=lambda x:x[1], reverse=False)\n",
    "diff_dict = dict(diff_dict)\n",
    "# print(diff_dict)\n",
    "\n",
    "lst = list(diff_dict.keys())\n",
    "# print(lst[0:5])\n",
    "\n",
    "print('Top 3 Recommended Chapters:')\n",
    "for i in range(0,len(lst)):\n",
    "    if i < 3:\n",
    "        print(f'{i+1}. {chapters_name[lst[i]]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
