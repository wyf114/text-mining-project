{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe55321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcf8b4",
   "metadata": {},
   "source": [
    "# Load LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8da5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_disk=gensim.models.ldamodel.LdaModel.load(\"Model/finalmodel_5Topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51f6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary.load('Model/finalmodel_Dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0edfa",
   "metadata": {},
   "source": [
    "# Extract & Preprocess Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b736a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus_1974 = preprocess.load_corpus('Data/Test/Chapters/1974')\n",
    "\n",
    "test_ids = test_corpus_1974.fileids()\n",
    "chapters_name = [id.replace('.txt','') for id in test_ids]\n",
    "\n",
    "test_docs_1974 = preprocess.corpus2docs(test_corpus_1974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bbfd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(bigram_mod, texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(bigram_mod, trigram_mod, texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c273180",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(test_docs_1974, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[test_docs_1974], threshold=50)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "docs_bigrams = make_bigrams(bigram_mod, test_docs_1974)\n",
    "data_bigrams_trigrams = make_trigrams(bigram_mod, trigram_mod, docs_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3fa2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs_1974 = preprocess.docs2vecs(data_bigrams_trigrams, id2word)\n",
    "similarity = similarities.MatrixSimilarity(lda_disk[test_vecs_1974])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f5dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test doc0: [(0, 0.01218065), (1, 0.35396844), (2, 0.11819526), (3, 0.48850587), (4, 0.027149793)]\n",
      "Closest Topic: Topic 3\n",
      "test doc1: [(0, 0.06205687), (1, 0.1359066), (2, 0.06236717), (3, 0.69744503), (4, 0.04222432)]\n",
      "Closest Topic: Topic 3\n",
      "test doc2: [(0, 0.03600633), (1, 0.34787714), (2, 0.0643663), (3, 0.4853912), (4, 0.066358976)]\n",
      "Closest Topic: Topic 3\n",
      "test doc3: [(0, 0.052230693), (1, 0.28845716), (2, 0.033839863), (3, 0.5125502), (4, 0.112922125)]\n",
      "Closest Topic: Topic 3\n",
      "test doc4: [(0, 0.025988597), (1, 0.042162128), (2, 0.12814552), (3, 0.7267955), (4, 0.07690824)]\n",
      "Closest Topic: Topic 3\n",
      "test doc5: [(0, 0.041118626), (1, 0.114718914), (2, 0.082272336), (3, 0.6925426), (4, 0.0693475)]\n",
      "Closest Topic: Topic 3\n",
      "test doc6: [(0, 0.09242194), (1, 0.31327662), (2, 0.1459558), (3, 0.36468288), (4, 0.083662726)]\n",
      "Closest Topic: Topic 3\n",
      "test doc7: [(0, 0.035176884), (2, 0.110975124), (3, 0.74904734), (4, 0.10462521)]\n",
      "Closest Topic: Topic 3\n",
      "test doc8: [(0, 0.035921), (1, 0.13626826), (2, 0.098987475), (3, 0.60325617), (4, 0.1255671)]\n",
      "Closest Topic: Topic 3\n",
      "test doc9: [(0, 0.079182796), (1, 0.14480436), (2, 0.04083305), (3, 0.47620738), (4, 0.25897244)]\n",
      "Closest Topic: Topic 3\n",
      "test doc10: [(0, 0.06354197), (1, 0.26366225), (2, 0.047033772), (3, 0.386211), (4, 0.23955104)]\n",
      "Closest Topic: Topic 3\n",
      "test doc11: [(1, 0.21925032), (2, 0.058440566), (3, 0.56779015), (4, 0.15424894)]\n",
      "Closest Topic: Topic 3\n",
      "test doc12: [(0, 0.016014064), (1, 0.098278955), (2, 0.15530214), (3, 0.56760806), (4, 0.16279681)]\n",
      "Closest Topic: Topic 3\n",
      "test doc13: [(0, 0.05176957), (1, 0.17753416), (2, 0.13525489), (3, 0.40344408), (4, 0.23199728)]\n",
      "Closest Topic: Topic 3\n",
      "test doc14: [(0, 0.057328977), (1, 0.049957156), (2, 0.09472864), (3, 0.726967), (4, 0.071018234)]\n",
      "Closest Topic: Topic 3\n",
      "test doc15: [(0, 0.067779794), (1, 0.020350853), (2, 0.04487479), (3, 0.55339843), (4, 0.31359613)]\n",
      "Closest Topic: Topic 3\n",
      "test doc16: [(1, 0.035745602), (2, 0.02620589), (3, 0.8950943), (4, 0.042885188)]\n",
      "Closest Topic: Topic 3\n",
      "test doc17: [(1, 0.040557064), (2, 0.010219502), (3, 0.9440076)]\n",
      "Closest Topic: Topic 3\n",
      "test doc18: [(1, 0.19314198), (2, 0.03891819), (3, 0.61731505), (4, 0.15024062)]\n",
      "Closest Topic: Topic 3\n",
      "test doc19: [(0, 0.014507258), (1, 0.09456173), (2, 0.09847896), (3, 0.68012726), (4, 0.112324774)]\n",
      "Closest Topic: Topic 3\n",
      "test doc20: [(0, 0.029778326), (1, 0.13167222), (2, 0.06032063), (3, 0.6987959), (4, 0.07943289)]\n",
      "Closest Topic: Topic 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    sim_topic = max(vector,key=lambda item:item[1])\n",
    "    print(\"test doc\" + str(i) + \": \" + str(vector))\n",
    "    print(\"Closest Topic: Topic \" + str(sim_topic[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f1ae0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conception', 0.03775606),\n",
       " ('zarathustra', 0.028077127),\n",
       " ('thou', 0.024449555),\n",
       " ('hath', 0.018459603),\n",
       " ('pure', 0.016960025),\n",
       " ('phenomenon', 0.015507126),\n",
       " ('thee', 0.0153419515),\n",
       " ('unto', 0.01463752),\n",
       " ('cognition', 0.013255156),\n",
       " ('intuition', 0.013230192),\n",
       " ('empirical', 0.010757555),\n",
       " ('social', 0.010513507),\n",
       " ('activity', 0.010492589),\n",
       " ('education', 0.0104921805),\n",
       " ('representation', 0.009958939),\n",
       " ('priori', 0.009342978),\n",
       " ('verily', 0.009038341),\n",
       " ('doth', 0.008945876),\n",
       " ('space', 0.008808358),\n",
       " ('transcendental', 0.008680221)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = lda_disk.show_topic(0, topn=len(id2word))\n",
    "topic_word[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def5c027",
   "metadata": {},
   "source": [
    "## Model 1 - Using Similarity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f39de",
   "metadata": {},
   "source": [
    "### Top Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863307a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_num = 4\n",
    "vector = lda_disk[test_vecs_1974[chap_num]]\n",
    "sim_topic = max(vector,key=lambda item:item[1])\n",
    "top_topic = sim_topic[0]\n",
    "top_topic\n",
    "topic_word = lda_disk.show_topic(top_topic, topn=len(id2word))\n",
    "# topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ffb899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'already',\n",
       " 'also',\n",
       " 'author',\n",
       " 'change',\n",
       " 'character',\n",
       " 'common',\n",
       " 'confine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_words = [id2word[i[0]] for i in test_vecs_1974[chap_num]]\n",
    "selected_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0813b3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('epic_poetry', 0.00058412395)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words = []\n",
    "\n",
    "keyword_type = 'bigrams'\n",
    "for word in topic_word:\n",
    "    if(keyword_type == 'unigrams'):\n",
    "        if (len(key_words) < 5) & (word [0] in selected_words):\n",
    "            key_words.append(word)\n",
    "    else:\n",
    "        if ('_' in word[0]) & (len(key_words) < 5) & (word [0] in selected_words):\n",
    "            key_words.append(word)\n",
    "\n",
    "key_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd48b8",
   "metadata": {},
   "source": [
    "### Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baf41b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Recommended Chapters:\n",
      "1. XVIII(0.9980166)\n",
      "2. XI(0.9974043)\n",
      "3. XXIV(0.9947127)\n"
     ]
    }
   ],
   "source": [
    "chap_num = 4\n",
    "\n",
    "chosen_chapter = chapters_name[chap_num]\n",
    "recommendation_scores = []\n",
    "\n",
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    sim_topic = max(vector,key=lambda item:item[1])\n",
    "    \n",
    "    if(i == chap_num):\n",
    "        sims = similarity[vector]\n",
    "        sims = list(enumerate(sims))\n",
    "        for sim in sims:\n",
    "            chapter_num = sim[0]\n",
    "            recommendation_score = [chapters_name[chapter_num], sim[1]]\n",
    "            recommendation_scores.append(recommendation_score)\n",
    "        \n",
    "recommendation_scores = sorted(recommendation_scores, key=lambda x: x[1], reverse=True)     \n",
    "recommendation = []\n",
    "\n",
    "\n",
    "print('Top 3 Recommended Chapters:')\n",
    "for i in range(1,4):\n",
    "    recommendation.append((recommendation_scores[i][0], recommendation_scores[i][1]))\n",
    "    print(f'{i}. {str(recommendation_scores[i][0])}({str(recommendation_scores[i][1])})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000b96f",
   "metadata": {},
   "source": [
    "## Model 2 - Using Distribution of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b311403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Recommended Chapters:\n",
      "1. I\n",
      "2. III\n",
      "3. IV\n"
     ]
    }
   ],
   "source": [
    "# if first digit in tuple matches, store doc\n",
    "# reco_docs -- dont remove user input\n",
    "# - get index of user input within reco_docs\n",
    "# - compare difference between first topic probability and store as list; e.g. {4: 0.002,...}\n",
    "# - take top 5 minimum difference\n",
    "\n",
    "j = 4\n",
    "vector_selected = lda_disk[test_vecs_1974[j]]\n",
    "vector_selected.sort(key=lambda x: x[1], reverse=True)\n",
    "vector_selected\n",
    "\n",
    "reco_docs = {}\n",
    "\n",
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    vector.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if (vector[0][0]==vector_selected[0][0]) & (vector[1][0] == vector_selected[1][0]):\n",
    "        reco_docs[i] = vector\n",
    "#         print(vector[0][1])\n",
    "\n",
    "# print(reco_docs)\n",
    "\n",
    "input_topic = reco_docs[j]\n",
    "\n",
    "# Remove user input\n",
    "if j in reco_docs.keys():\n",
    "    reco_docs.pop(j)\n",
    "\n",
    "diff = \"\"\n",
    "diff_dict = {}\n",
    "for x, y in reco_docs.items():\n",
    "    diff = abs(input_topic[0][1] - reco_docs[x][0][1])\n",
    "    diff_dict[x] = diff\n",
    "\n",
    "diff_dict = sorted(diff_dict.items(), key=lambda x:x[1], reverse=False)\n",
    "diff_dict = dict(diff_dict)\n",
    "# print(diff_dict)\n",
    "\n",
    "lst = list(diff_dict.keys())\n",
    "lst[0:5]\n",
    "\n",
    "print('Top 3 Recommended Chapters:')\n",
    "for i in range(0,3):\n",
    "    print(f'{i+1}. {chapters_name[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
