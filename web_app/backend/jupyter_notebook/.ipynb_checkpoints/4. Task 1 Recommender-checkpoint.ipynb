{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c36f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4404622",
   "metadata": {},
   "source": [
    "# Load LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "298bf65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_disk=gensim.models.ldamodel.LdaModel.load(\"Model/finalmodel_5Topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13ac1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary.load('Model/finalmodel_Dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb20433",
   "metadata": {},
   "source": [
    "# Extract & Preprocess Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9dcd2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus_1974 = preprocess.load_corpus('Data/Test/Chapters/65145')\n",
    "\n",
    "test_ids = test_corpus_1974.fileids()\n",
    "chapters_name = [id.replace('.txt','') for id in test_ids]\n",
    "\n",
    "test_docs_1974 = preprocess.corpus2docs(test_corpus_1974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f70ffbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(test_docs_1974, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[test_docs_1974], threshold=50)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "docs_bigrams = preprocess.make_bigrams(bigram_mod, test_docs_1974)\n",
    "data_bigrams_trigrams = preprocess.make_trigrams(bigram_mod, trigram_mod, docs_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0945f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs_1974 = preprocess.docs2vecs(data_bigrams_trigrams, id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2179b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test doc0: [(0, 0.18936343), (1, 0.19214727), (2, 0.4796575), (3, 0.04631623), (4, 0.09251558)]\n",
      "Closest Topic: Topic 2\n",
      "test doc1: [(0, 0.21943788), (1, 0.19598562), (2, 0.4601555), (3, 0.05499007), (4, 0.069430985)]\n",
      "Closest Topic: Topic 2\n",
      "test doc2: [(0, 0.071723804), (1, 0.12538402), (2, 0.61917436), (3, 0.036313046), (4, 0.14740476)]\n",
      "Closest Topic: Topic 2\n",
      "test doc3: [(0, 0.120798655), (1, 0.09923056), (2, 0.4659989), (3, 0.026383515), (4, 0.28758836)]\n",
      "Closest Topic: Topic 2\n",
      "test doc4: [(0, 0.11447893), (1, 0.109432764), (2, 0.6373774), (3, 0.031578), (4, 0.10713297)]\n",
      "Closest Topic: Topic 2\n",
      "test doc5: [(0, 0.177121), (1, 0.1686131), (2, 0.51068825), (3, 0.028049905), (4, 0.11552779)]\n",
      "Closest Topic: Topic 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    sim_topic = max(vector,key=lambda item:item[1])\n",
    "    print(\"test doc\" + str(i) + \": \" + str(vector))\n",
    "    print(\"Closest Topic: Topic \" + str(sim_topic[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a30a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conception', 0.032495115),\n",
       " ('zarathustra', 0.024165511),\n",
       " ('thou', 0.021026777),\n",
       " ('hath', 0.015878359),\n",
       " ('pure', 0.014599969),\n",
       " ('phenomenon', 0.013353135),\n",
       " ('thee', 0.013118728),\n",
       " ('unto', 0.012600138),\n",
       " ('cognition', 0.011412212),\n",
       " ('intuition', 0.011389661),\n",
       " ('empirical', 0.00927787),\n",
       " ('social', 0.009052046),\n",
       " ('education', 0.009046041),\n",
       " ('activity', 0.009034674),\n",
       " ('representation', 0.008575148),\n",
       " ('priori', 0.0080437185),\n",
       " ('verily', 0.007781609),\n",
       " ('doth', 0.00770331),\n",
       " ('space', 0.007673117),\n",
       " ('transcendental', 0.0074760346)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = lda_disk.show_topic(0, topn=len(id2word))\n",
    "topic_word[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120891f",
   "metadata": {},
   "source": [
    "## Model 1 - Using Similarity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f8cee",
   "metadata": {},
   "source": [
    "### Top Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95967374",
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_num = 0\n",
    "vector = lda_disk[test_vecs_1974[chap_num]]\n",
    "sim_topic = max(vector,key=lambda item:item[1])\n",
    "top_topic = sim_topic[0]\n",
    "top_topic\n",
    "topic_word = lda_disk.show_topic(top_topic, topn=len(id2word))\n",
    "# topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c6fd86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'accessory',\n",
       " 'accompany',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'achievement',\n",
       " 'acknowledge']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_words = [id2word[i[0]] for i in test_vecs_1974[chap_num]]\n",
    "selected_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f6c4fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('outer_world', 0.00080459705),\n",
       " ('natural_selection', 9.627251e-06),\n",
       " ('reproductive_organ', 6.3105076e-06),\n",
       " ('male_female', 6.2402873e-06),\n",
       " ('internal_secretion', 6.216118e-06)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words = []\n",
    "\n",
    "keyword_type = 'bigrams'\n",
    "for word in topic_word:\n",
    "    if(keyword_type == 'unigrams'):\n",
    "        if (len(key_words) < 5) & (word [0] in selected_words):\n",
    "            key_words.append(word)\n",
    "    else:\n",
    "        if ('_' in word[0]) & (len(key_words) < 5) & (word [0] in selected_words):\n",
    "            key_words.append(word)\n",
    "\n",
    "key_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa4c93",
   "metadata": {},
   "source": [
    "### Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c838e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'II', 'III', 'IV', 'V', 'VI']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9e0a628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Recommended Chapters:\n",
      "1. III(0.9955205)\n",
      "2. VI(0.9793974)\n",
      "3. I(0.96451896)\n"
     ]
    }
   ],
   "source": [
    "chap_num = 4\n",
    "\n",
    "chosen_chapter = chapters_name[chap_num]\n",
    "recommendation_scores = []\n",
    "similarity = similarities.MatrixSimilarity(lda_disk[test_vecs_1974])\n",
    "\n",
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    sim_topic = max(vector,key=lambda item:item[1])\n",
    "    \n",
    "    if(i == chap_num):\n",
    "        sims = similarity[vector]\n",
    "        sims = list(enumerate(sims))\n",
    "        for sim in sims:\n",
    "            chapter_num = sim[0]\n",
    "            recommendation_score = [chapters_name[chapter_num], sim[1]]\n",
    "            recommendation_scores.append(recommendation_score)\n",
    "        \n",
    "recommendation_scores = sorted(recommendation_scores, key=lambda x: x[1], reverse=True)     \n",
    "recommendation = []\n",
    "\n",
    "\n",
    "print('Top 3 Recommended Chapters:')\n",
    "for i in range(1,4):\n",
    "    recommendation.append((recommendation_scores[i][0], recommendation_scores[i][1]))\n",
    "    print(f'{i}. {str(recommendation_scores[i][0])}({str(recommendation_scores[i][1])})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a80ecb",
   "metadata": {},
   "source": [
    "## Model 2 - Using Distribution of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c72f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER_III__THE_NATURE_OF_MATTER',\n",
       " 'CHAPTER_II__THE_EXISTENCE_OF_MATTER',\n",
       " 'CHAPTER_IV__IDEALISM',\n",
       " 'CHAPTER_IX__THE_WORLD_OF_UNIVERSALS',\n",
       " 'CHAPTER_I__APPEARANCE_AND_REALITY',\n",
       " 'CHAPTER_VIII__HOW__A_PRIORI__KNOWLEDGE_IS_POSSIBLE',\n",
       " 'CHAPTER_VII__ON_OUR_KNOWLEDGE_OF_GENERAL_PRINCIPLES',\n",
       " 'CHAPTER_VI__ON_INDUCTION',\n",
       " 'CHAPTER_V__KNOWLEDGE_BY_ACQUAINTANCE_AND_KNOWLEDGE_BY_DESCRIPTION',\n",
       " 'CHAPTER_XIII__KNOWLEDGE,_ERROR,_AND_PROBABLE_OPINION',\n",
       " 'CHAPTER_XII__TRUTH_AND_FALSEHOOD',\n",
       " 'CHAPTER_XIV__THE_LIMITS_OF_PHILOSOPHICAL_KNOWLEDGE',\n",
       " 'CHAPTER_XI__ON_INTUITIVE_KNOWLEDGE',\n",
       " 'CHAPTER_X__ON_OUR_KNOWLEDGE_OF_UNIVERSALS']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fced31d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Recommended Chapters:\n",
      "1. VI\n",
      "2. II\n"
     ]
    }
   ],
   "source": [
    "# if first digit in tuple matches, store doc\n",
    "# reco_docs -- dont remove user input\n",
    "# - get index of user input within reco_docs\n",
    "# - compare difference between first topic probability and store as list; e.g. {4: 0.002,...}\n",
    "# - take top 5 minimum difference\n",
    "\n",
    "j = 4\n",
    "vector_selected = lda_disk[test_vecs_1974[j]]\n",
    "vector_selected.sort(key=lambda x: x[1], reverse=True)\n",
    "vector_selected\n",
    "\n",
    "reco_docs = {}\n",
    "\n",
    "for i in range(0,len(test_vecs_1974)):\n",
    "    vector = lda_disk[test_vecs_1974[i]]\n",
    "    vector.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if (vector[0][0]==vector_selected[0][0]) & (vector[1][0] == vector_selected[1][0]):\n",
    "        reco_docs[i] = vector\n",
    "        # print(vector[0][1])\n",
    "\n",
    "# print(reco_docs)\n",
    "input_topic = reco_docs[j]\n",
    "\n",
    "# Remove user input\n",
    "if j in reco_docs.keys():\n",
    "    reco_docs.pop(j)\n",
    "\n",
    "# if there's no 2 same topics\n",
    "if reco_docs == {}:\n",
    "    for i in range(0,len(test_vecs_1974)):\n",
    "        vector = lda_disk[test_vecs_1974[i]]\n",
    "        vector.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        if (vector[0][0]==vector_selected[0][0]):\n",
    "            reco_docs[i] = vector\n",
    "\n",
    "    # Remove user input\n",
    "    if j in reco_docs.keys():\n",
    "        reco_docs.pop(j)\n",
    "\n",
    "diff = \"\"\n",
    "diff_dict = {}\n",
    "for x, y in reco_docs.items():\n",
    "    diff = abs(input_topic[0][1] - reco_docs[x][0][1])\n",
    "    diff_dict[x] = diff\n",
    "\n",
    "diff_dict = sorted(diff_dict.items(), key=lambda x:x[1], reverse=False)\n",
    "diff_dict = dict(diff_dict)\n",
    "# print(diff_dict)\n",
    "\n",
    "lst = list(diff_dict.keys())\n",
    "# print(lst[0:5])\n",
    "\n",
    "print('Top 3 Recommended Chapters:')\n",
    "for i in range(0,len(lst)):\n",
    "    if i < 3:\n",
    "        print(f'{i+1}. {chapters_name[lst[i]]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
